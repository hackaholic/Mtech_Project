{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# GAN Discriminator (Xception Backbone) for AI vs Real Image Detection\n",
                "\n",
                "This notebook implements an **Xception-based Discriminator** to classify images as Real vs AI.\n",
                "**Xception** is widely regarded as a benchmark architecture for DeepFake and AI Image detection.\n",
                "It also includes system performance monitoring (**CPU, RAM, Disk I/O, and GPU**) during training.\n",
                "\n",
                "## 1. Imports and Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install datasets pandas pyarrow psutil matplotlib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import time\n",
                "import psutil\n",
                "import threading\n",
                "import subprocess\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers, models, applications\n",
                "from datasets import load_dataset\n",
                "from PIL import Image\n",
                "import io\n",
                "\n",
                "# Check for GPU\n",
                "print(\"TensorFlow version:\", tf.__version__)\n",
                "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. System Performance Monitoring\n",
                "We use a background thread to log CPU, RAM, Disk, and GPU usage during training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SystemMonitor:\n",
                "    def __init__(self, interval=1.0):\n",
                "        self.interval = interval\n",
                "        self.stop_event = threading.Event()\n",
                "        self.history = {\n",
                "            'timestamp': [],\n",
                "            'cpu_percent': [],\n",
                "            'ram_percent': [],\n",
                "            'gpu_percent': [],\n",
                "            'gpu_mem': [],\n",
                "            'disk_read': [],\n",
                "            'disk_write': []\n",
                "        }\n",
                "        self.thread = threading.Thread(target=self._monitor_loop)\n",
                "\n",
                "    def _get_gpu_metrics(self):\n",
                "        try:\n",
                "            # Uses nvidia-smi to get GPU utilization and Memory usage\n",
                "            result = subprocess.check_output(\n",
                "                ['nvidia-smi', '--query-gpu=utilization.gpu,memory.used', '--format=csv,noheader,nounits'],\n",
                "                encoding='utf-8'\n",
                "            )\n",
                "            # Output example: \"45, 1024\" -> 45% util, 1024MB mem\n",
                "            util, mem = map(int, result.strip().split(','))\n",
                "            return util, mem\n",
                "        except Exception:\n",
                "            # Fallback if nvidia-smi is missing\n",
                "            return 0, 0\n",
                "\n",
                "    def _monitor_loop(self):\n",
                "        # Initial disk counters\n",
                "        last_disk = psutil.disk_io_counters()\n",
                "        start_time = time.time()\n",
                "        \n",
                "        while not self.stop_event.is_set():\n",
                "            current_time = time.time() - start_time\n",
                "            cpu = psutil.cpu_percent(interval=None)\n",
                "            ram = psutil.virtual_memory().percent\n",
                "            gpu_util, gpu_mem = self._get_gpu_metrics()\n",
                "            \n",
                "            if last_disk:\n",
                "                current_disk = psutil.disk_io_counters()\n",
                "                disk_read = (current_disk.read_bytes - last_disk.read_bytes) / 1024 / 1024 # MB\n",
                "                disk_write = (current_disk.write_bytes - last_disk.write_bytes) / 1024 / 1024 # MB\n",
                "                last_disk = current_disk\n",
                "            else:\n",
                "                disk_read, disk_write = 0, 0\n",
                "            \n",
                "            self.history['timestamp'].append(current_time)\n",
                "            self.history['cpu_percent'].append(cpu)\n",
                "            self.history['ram_percent'].append(ram)\n",
                "            self.history['gpu_percent'].append(gpu_util)\n",
                "            self.history['gpu_mem'].append(gpu_mem)\n",
                "            self.history['disk_read'].append(disk_read)\n",
                "            self.history['disk_write'].append(disk_write)\n",
                "            \n",
                "            time.sleep(self.interval)\n",
                "\n",
                "    def start(self):\n",
                "        self.stop_event.clear()\n",
                "        self.thread = threading.Thread(target=self._monitor_loop) # Recreate thread if restarted\n",
                "        self.thread.start()\n",
                "        print(\"System monitoring started...\")\n",
                "\n",
                "    def stop(self):\n",
                "        self.stop_event.set()\n",
                "        self.thread.join()\n",
                "        print(\"System monitoring stopped.\")\n",
                "        \n",
                "    def plot(self):\n",
                "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\n",
                "        \n",
                "        # CPU & RAM\n",
                "        ax1.plot(self.history['timestamp'], self.history['cpu_percent'], label='CPU %')\n",
                "        ax1.plot(self.history['timestamp'], self.history['ram_percent'], label='RAM %')\n",
                "        ax1.set_title('CPU & RAM Usage')\n",
                "        ax1.set_xlabel('Time (s)')\n",
                "        ax1.set_ylabel('Percentage')\n",
                "        ax1.legend()\n",
                "        ax1.grid(True)\n",
                "\n",
                "        # GPU\n",
                "        ax2.plot(self.history['timestamp'], self.history['gpu_percent'], label='GPU %', color='red')\n",
                "        ax2.set_ylabel('Utilization %', color='red')\n",
                "        ax2_mem = ax2.twinx()\n",
                "        ax2_mem.plot(self.history['timestamp'], self.history['gpu_mem'], label='GPU Mem (MB)', color='orange', linestyle='--')\n",
                "        ax2_mem.set_ylabel('Memory (MB)', color='orange')\n",
                "        ax2.set_title('GPU Usage')\n",
                "        ax2.set_xlabel('Time (s)')\n",
                "        ax2.grid(True)\n",
                "        \n",
                "        # Disk I/O\n",
                "        ax3.plot(self.history['timestamp'], self.history['disk_read'], label='Disk Read (MB)')\n",
                "        ax3.plot(self.history['timestamp'], self.history['disk_write'], label='Disk Write (MB)')\n",
                "        ax3.set_title('Disk I/O (MB per interval)')\n",
                "        ax3.set_xlabel('Time (s)')\n",
                "        ax3.set_ylabel('MB')\n",
                "        ax3.legend()\n",
                "        ax3.grid(True)\n",
                "        \n",
                "        plt.show()\n",
                "\n",
                "# Create monitor instance\n",
                "monitor = SystemMonitor(interval=1.0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Configuration & Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Paths\n",
                "DATA_FILES = {\n",
                "    \"train\": \"/storage/AIGeneratedImages_Midjourney/data/train-*.parquet\",\n",
                "    \"validation\": \"/storage/AIGeneratedImages_Midjourney/data/validation-*.parquet\",\n",
                "    \"test\": \"/storage/AIGeneratedImages_Midjourney/data/test-*.parquet\",\n",
                "}\n",
                "\n",
                "# Hyperparameters\n",
                "IMG_SIZE = (224, 224) # Xception expects approx 299x299 usually, but 224 is compatible.\n",
                "BATCH_SIZE = 128 # Optimized for P5000\n",
                "LEARNING_RATE = 0.0001 # Slightly lower for fine-tuning\n",
                "NUM_EPOCHS = 5 # Reduced\n",
                "SEED = 42"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Loading dataset from parquet...\")\n",
                "dataset = load_dataset(\n",
                "    \"parquet\",\n",
                "    data_files=DATA_FILES\n",
                ")\n",
                "\n",
                "def process_example(example):\n",
                "    from PIL import Image\n",
                "    import io\n",
                "    img_data = example['image']\n",
                "    try:\n",
                "        if isinstance(img_data, bytes):\n",
                "             image = Image.open(io.BytesIO(img_data))\n",
                "        elif isinstance(img_data, dict) and 'bytes' in img_data:\n",
                "             image = Image.open(io.BytesIO(img_data['bytes']))\n",
                "        else:\n",
                "             image = img_data\n",
                "        \n",
                "        if not isinstance(image, Image.Image):\n",
                "             if isinstance(image, str):\n",
                "                 image = Image.open(image)\n",
                "    except Exception as e:\n",
                "        image = Image.new('RGB', IMG_SIZE)\n",
                "    \n",
                "    image = image.convert(\"RGB\").resize(IMG_SIZE)\n",
                "\n",
                "    # Xception Preprocessing expects [-1, 1]. \n",
                "    # keras.applications.xception.preprocess_input does this.\n",
                "    # We will do it in model or here. Let's return raw array and let valid preprocessing happen in model.\n",
                "    return np.array(image), example['label']\n",
                "\n",
                "def tf_data_generator(split_name):\n",
                "    def generator():\n",
                "        for example in dataset[split_name]:\n",
                "            yield process_example(example)\n",
                "    return generator\n",
                "\n",
                "def create_tf_dataset(split_name):\n",
                "    return tf.data.Dataset.from_generator(\n",
                "        tf_data_generator(split_name),\n",
                "        output_signature=(\n",
                "            tf.TensorSpec(shape=(IMG_SIZE[0], IMG_SIZE[1], 3), dtype=tf.uint8),\n",
                "            tf.TensorSpec(shape=(), dtype=tf.int64)\n",
                "        )\n",
                "    )\n",
                "\n",
                "train_ds = create_tf_dataset('train')\n",
                "val_ds = create_tf_dataset('validation')\n",
                "test_ds = create_tf_dataset('test')\n",
                "\n",
                "AUTOTUNE = tf.data.AUTOTUNE\n",
                "train_ds = train_ds.shuffle(1000).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
                "val_ds = val_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
                "test_ds = test_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Architecture: Xception Discriminator\n",
                "Using Xception pretrained on ImageNet."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_xception_discriminator():\n",
                "    # Base model\n",
                "    base_model = applications.Xception(\n",
                "        include_top=False,\n",
                "        weights=\"imagenet\",\n",
                "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
                "    )\n",
                "    \n",
                "    # Freeze base model initially\n",
                "    base_model.trainable = False\n",
                "\n",
                "    inputs = keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
                "    \n",
                "    # Preprocessing for Xception (scale to [-1, 1])\n",
                "    x = applications.xception.preprocess_input(inputs)\n",
                "    \n",
                "    # Augmentation\n",
                "    x = layers.RandomFlip(\"horizontal\")(x)\n",
                "    x = layers.RandomRotation(0.05)(x)\n",
                "    \n",
                "    x = base_model(x, training=False)\n",
                "    x = layers.GlobalAveragePooling2D()(x)\n",
                "    x = layers.Dropout(0.3)(x)\n",
                "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
                "    \n",
                "    model = keras.Model(inputs, outputs, name=\"Xception_Discriminator\")\n",
                "    return model\n",
                "\n",
                "model = build_xception_discriminator()\n",
                "model.summary()\n",
                "\n",
                "model.compile(\n",
                "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
                "    loss='binary_crossentropy',\n",
                "    metrics=['accuracy', keras.metrics.Precision(name='precision'), keras.metrics.Recall(name='recall')]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Training with Monitoring"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "monitor.start()\n",
                "\n",
                "try:\n",
                "    history = model.fit(\n",
                "        train_ds,\n",
                "        validation_data=val_ds,\n",
                "        epochs=NUM_EPOCHS,\n",
                "        callbacks=[\n",
                "            keras.callbacks.ModelCheckpoint(\"gan_xception_best.keras\", save_best_only=True),\n",
                "            keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
                "        ]\n",
                "    )\n",
                "finally:\n",
                "    monitor.stop()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize System Performance\n",
                "monitor.plot()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Evaluating on Test Set...\")\n",
                "results = model.evaluate(test_ds)\n",
                "print(f\"Test Accuracy: {results[1]:.4f}\")\n",
                "print(f\"Test Precision: {results[2]:.4f}\")\n",
                "print(f\"Test Recall: {results[3]:.4f}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}